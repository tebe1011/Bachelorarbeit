%% ===========================
\chapter{Analyse ausgewählter Datenbanken}
\label{ch:AnalyseDatenbanken}
%% ===========================

Ein Ziel der Bachelor Thesis ist es, hohe Performance in der Beantwortung der Benutzeranfragen zu erreichen. Die maßgebende Komponente ist in diesem Fall die Datenbank. Sie führt die zeitintensiven Ermittlungen, Berechnungen und Filterungen des Gesamtsystems durch. Um Anhaltspunkte für mögliche Kandidaten zu bekommen, sollen im folgenden eine Reihe aus der Literatur bekannte Datenbanken vorgestellt und gegenübergestellt werden. Bei der Zusammenstellung wurde darauf geachtet, dass ein möglichst weites Spektrum unterschiedlicher Datenbanken ausgewählt wurde.

%% ===========================
\section{Datenbanken}
\label{ch:AnalyseDatenbanken}
%% ===========================

Im folgenden werden nun einige aus der Literatur bekannte Datenbanken vorgestellt. Dabei wird insbesondere versucht, einen guten Überblick über die Charakteristika der einzelnen Datenbanken zu geben. Der dahinter stehende Gedanken ist, dass ein späterer Vergleich und Entschluss zur Nutzung besser nachvollziehbar sind. 

%% ===========================
\subsection{CouchDB}
%% ===========================

CouchDB \cite{couch2013} ist eine dokumentenorientierten Datenbank die seit Anfang 2008 unter der  Apache-Lizenz verbreitet wird. In CouchDB werden die Daten in Collections anstatt in Tabellen abgelegt. Collections bestehen aus einer Sammlung von unabhängigen Dokumenten. Jedes Dokument verwaltet seine eigenen Daten in einem freien Schema. 
Ein Dokument hat Feldwerte, die Datentypen (Text, numerisch oder boolean) oder Datenstrukturen (ein Dokument oder Liste) beinhalten. Abfragen werden mit "views" zum Filtern der Dokumente ausgeführt. Indizes sind in CouchDB B-Bäume, so dass die Ergebnisse sortiert und Wertebereich-Anfragen ausgeführt werden können. Abfragen können parallel über mehrere Knoten mit einem MapReduce Mechanismus verteilt werden. CouchDB erreicht Skalierbarkeit durch asynchrone Replikation nicht durch Fragmentierung. Lesezugriffe können auf beliebigen Server stattfinden, wenn Aktualität keine Rolle spielt. Updates hingegen müssen an alle Server weitergegeben werden.
CouchDB unterscheidet sich von anderen Systemen dadurch, dass es Eventual Consistency akzeptiert. Jeder Client erhält eine in sich selbst konsistente Ansicht der Datenbank. CouchDB implementiert Multi-Version Concurrency Control (MVCC) auf einzelne Dokumente mit einer Sequenz-ID die für jede Version eines Dokuments generiert wird. CouchDB benachrichtigt eine Anwendung, wenn jemand anderes das Dokument aktualisiert hat seit dem es zuletzt gefetched wurde. Die Anwendung kann dann versuchen, die Updates zu kombinieren oder das Update zu wiederholen um die Daten zu überschreiben. CouchDB erfüllt damit im lokalen Einsatz die ACID-Eigenschaften. Jede Transaktion ist eine in sich abgeschlossene Operation, die entweder ganz oder gar nicht ausgeführt wird. Es treten keine Seiteneffekte zwischen den Anfragen auf. Außerdem wird die Datenbank immer in einem konsistenten Zustand hinterlassen

%% ===========================
\subsection{MongoDB}
%% ===========================

MongoDB ist ein in C + + geschrieben Open Source Document Store \cite{books/daglib/0025185}. Es hat einige Ähnlichkeiten mit CouchDB. Beide bietet Indizes auf Collections, sie sind lockless, und bieten einen Dokument-Abfragemechanismus. Es gibt jedoch wichtige Unterschiede:

\begin{itemize}

	\item MongoDB unterstützt automatische Fragmentierung die Dokumenten über Server verteilt.
	\item Dynamische Abfragen mit automatischer Verwendung von Indizes werden von MongoDB unterstützt. In CouchDB werden durch das Schreiben von map-reduce views Daten indiziert und gesucht.
	\item CouchDB nutzt MVCC bei Dokumenten, MongoDB hingegen nutzt atomare Operation auf Feldern    

\end{itemize}

MongoDB speichert Daten in einem JSON-ähnlichen binären Format namens BSON. BSON unterstützt boolean, integer, float, Datum, String-und Binär-Typen. Client-Treiber verschlüsseln die lokalen Dokumentendatenstruktur in das BSON Format und senden es an den MongoDB Server. Weiterhin unterstützt MongoDB die GridFS Spezifikation für große binär Dateien wie z.B. Filme oder Bilder. MongoDB unterstützt Master-Slave-Replikation mit automatischem Failover und Recovery. Replikation (und Wiederherstellung) basieren auf dem Prinzip der Fragmentierung. Collections werden über einen benutzerdefinierten Schlüssel automatisch fragmentiert. Die Replikation ist asynchron für höhere Leistung, jedoch können einige Updates bei einem Crash verloren gehen. 

%% ===========================
\subsection{Voldemort}
%% ===========================

Projekt Voldemort \cite{vod2013} ist ein verteilter Key-Value-Store (entwickelt von LinkedIn), der ein hoch skalierbares Speicher-System zur Verfügung stellt. Voldemort repliziert sich durch automatisches partitionieren und anschließendes verteilen der Daten auf multiple Server. Jeder Server stellt einen unabhängigen Knoten im System dar, der für die Verwaltung seiner Daten verantwortlich ist. Dadurch existiert kein Single Point of Failure im Cluster. Ein solches Daten Model erlaubt eine Cluster Expansion ohne eine Neuverteilung der Daten vornehmen zu müssen. In Voldemort können verschiedene Storage Systeme wie BerkeleyDB oder MySQL eingesetzt werden. 

Für die Ablage der Daten werden in Voldemort sogenannte Stores verwendet. Unterstützt werden lediglich Key-Value Ablagen. Jedoch können values komplexere Datenstrukturen wie Maps oder Listen beinhalten. Voldemort stellt 4 verschiedene Operatoren zur Datenmanipulation bereit:

\begin{itemize}

	\item PUT (Key,Value)
	\item GET (Key)
	\item MULTI-GET (Keys)
	\item DELETE (Key, Version) 

\end{itemize}

Eine Möglichkeit für Range Scans ist dabei nicht vorhanden. Der Parameter Version im DELETE-Operator dient der Unterscheidung der Datensätze und ist auf das Verfahren zur Gewährleistung der Konsistenz zurückzuführen. Zur Gewährleistung der eventuellen Konsistenz werden Timestamps und die Vector Clock Technik eingesetzt. Neben der eventuellen Konsistenz bietet Voldemort einen Betrieb mit starker Konsistenz an.       

%% ===========================
\subsection{Redis}
%% ===========================

Redis \cite{red2013} ist ein In-Memory-, Key-Value-Store mit einer Option für Persistenz. Redis Datenmodell unterstützt Strings, Hashes, Listen, Mengen und sortierte Mengen. Obwohl Redis für In-Memory-Daten entworfen wurde, kann je nach Anwendungsfall ein (semi-) persistenter Bestand angelegt werden. Entweder durch Momentaufnahmen der Daten und anschließendes ablegen auf der Festplatte in regelmäßigen Abständen oder durch Aufzeichnen eines Logs mit allen ausgeführten Operationen. Weiterhin kann Redis mit einem Master-Slave-Architektur repliziert werden. Genau wie andere Key-Value-Stores implementiert Redis insert, delete und lookup Operatoren. Weiterhin setzt Redis atomare Updates durch locking um. 

%% ===========================
\subsection{HBase} 
%% ===========================

HBase ist eine verteiltes Open Source Column Store Datenbanksystem welches auf Googles BigTable basiert \cite{Chang:2006:BDS:1267308.1267323}. HBase läuft auf Apache Hadoop und Apache ZooKeeper  \cite{Hunt:2010:ZWC:1855840.1855851} und verwendet das Hadoop Distributed Filesystem (HDFS) \cite{Shvachko:2010:HDF:1913798.1914427}, um Störung-Toleranz und Replikation zu bieten. Zeilen Operationen sind in HBase atomar, mit Sperren auf Zeilenebene und Transaktionen. Partitionierung und Verteilung sind transparent, da es keine Client-Seitiges Hashing oder feste Schlüsselräume wie in einigen NoSQL-Systeme gibt. 
Insbesondere stellt es lineare und modulare Skalierbarkeit sowie streng konsistenten Datenzugriff und automatisches und konfigurierbares Fragmentierung von Daten zu Verfügung. Auf Tabellen können in HBase über eine API zugegriffen werden. Sie können jedoch auch als Ein-und Ausgang Daten für MapReduce-Jobs in Hadoop verwendet werden. Anwendungen speichern in HBase Daten in Tabellen, die aus Zeilen und Spalten Familien bestehen. Spalten Familien beinhalten wiederum Spalten. Darüber hinaus kann jede Zeile einen anderen Satz von Spalten beinhalten. Alle Spalten sind mit einem vom Benutzer bereitgestellten Schlüsselspalte indiziert und in Spalte Familien gruppiert.

%% ===========================
\subsection{Cassandra} 
%% ===========================
Apache Cassandra ist eine verteilte Column Store Datenbank die von Facebook entwickelt wurde \cite{Lakshman:2010:CDS:1773912.1773922}. Sie ist eine Mischung aus Amazon Dynamo und Google BigTable wodurch sie des öfteren als Hybrid zwischen Key-Value-Store und Column Store bezeichnet wird. Cassandra wurde entwickelt um große Daten-Workloads über mehrere Knoten ohne Single Point of Failure zu behandeln. Die Architektur ist von der Annahme geprägt das System-und Hardware-Fehler auftreten können und auch wirklich auftreten. Cassandra behandelt das Problem von Fehlern durch Verwendung eines Peer-to-Peer-System, in dem alle Knoten gleich sind und die Daten von allen Knoten des Clusters verteilt werden. Jeder Knoten tauscht Informationen über das Cluster im Sekunden Takt aus. Ein Commit-Log auf jedem Knoten fängt Schreibaktivität ab um Daten Haltbarkeit zu gewährleisten. Daten werden auch auf eine In-Memory Struktur geschrieben, die memtable. Anschließend in eine Datendatei auf der Festplatte geschrieben genannt SSTable , sobald die Speicherstruktur voll ist. Alle Schreibvorgänge werden automatisch aufgeteilt und in Cluster repliziert. 

Cassandras Datenmodell basiert auf einem partitionierten Row-Store mit variabler Konsistenz. Zeilen werden in Tabellen organisiert, die erste Komponente des Primärschlüssels einer Tabelle ist der Partition Schlüssel. Innerhalb einer Partition werden Zeilen nach den verbliebenen Spalten des Primärschlüssels geclustert. Andere Spalten können getrennt von dem Primärschlüssel indiziert werden. Was Cassandra von HBase unterscheidet sind Spalten, die in einer verschachtelten Weise in Spalte Familien gruppiert werden können. Konsistenz Anforderungen, die zum Zeitpunkt der Abfrage angegeben werden können stellen auch ein Unterscheidungsmerkmal dar. Weiterhin ist Cassandra ein schreiborientiertes System während HBase entwickelt wurde um hohe Leistung für intensive Lese Workloads zu erzielen.

%% ===========================
\subsection{VoltDB} 
%% ===========================

VoltDB \cite{volt2013a} ist ein ACID-konformes relationales In-Memory-Datenbanksystem abgeleitet vom Forschungsprototyp H-Store \cite{kallman08}. Es basiert auf einer Shared-Nothing-Architektur und wurde entwickelt, um auf einem Cluster mit mehreren Knoten zu laufen. Dies wird erreicht indem man die Datenbank in getrennte Partitionen aufteilt bei dem jeder Knoten der Besitzer und Verantwortliche für die jeweiligen Partitionen ist. Durch Verwendung von Stored procedures als Transaktionseinheit, werden Round-Trip-Messages zwischen SQL Anfragen verhindert. Die Anfragen werden seriell in einem einzigen Thread ausgeführt sodass kein locking and latching mehr notwendig ist \cite{volt2013b}. Die Daten werden im Arbeitsspeicher gehalten, was eine Ausführung ohne Netzwerkzugriff und I/O Vorgänge ermöglicht, falls die Daten nur auf einem Knoten liegen.  

%% ===========================
\subsection{H2} 
%% ===========================

H2 ist ein in Java geschriebenes relationales Datenbanksystem, das im Jahre 2004 von Thomas Müller veröffentlicht wurde. Es wird unter der Eclipse Public License verbreitet und ist damit Open Source. H2 bietet neben den festplattenbasierten Tabellen auch eine In-Memory Variante an. Tabellen können dabei dauerhaft oder temporär sein. Weiterhin beherrscht H2 referenzielle Integrität, Transaktionen, Clustering, Datenkompression, Verschlüsselung und SSL. Die Datenbank kann im Embedded- oder Server-Modus betrieben werden.

%% ===========================
\section{Gegenüberstellung} 
\label{ch:AnalyseDatenbanken:sec:Gegenüberstellung}
%% ===========================

Um eine übersichtliche Gegenüberstellung der Datenbanken zu erreichen wurde die Tabelle \ref{tb_charakteristika} angefertigt. Sie enthält vergleichbare Eigenschaften von Datenbanken auf die im folgenden eingegangen wird. 

Die erste Eigenschaft ist das Erscheinungsjahr. Der Grund für die Aufnahme ist das Datenbanken die länger auf dem Markt sind meist eine höhere Reife aufweisen können. Bewährte Datenbanken haben bereits viele Ihrer anfänglichen Probleme behoben was den Umgang mit Ihnen erleichtert. Natürlich sind ältere Systeme nicht frei von Fehlern jedoch existieren für diese viele Workarounds oder andere Lösungsansätze. Cassandra zum Beispiel hat neben zahlreichen Bugfixes über die Jahre CQL als Query Sprache, MapReduce Support, sekundäre Indizies, verbesserte Komprimierung und vieles weiteres erhalten. Es gibt keine feste Regel die besagt wann ein System die Reife für den produktiven Einsatz erreicht hat. Es spielen natürlich auch andere Faktoren bei der Bestimmung der Ausgereiftheit eine Rolle, wie z.B. die Größe des Unternehmens oder Teams das hinter der Datenbank steht. Die Eigenschaft hat weniger den Zweck eines Kriteriums sondern eher eines Indikators. 

Eine wichtige Rolle spielt jedoch die Lizenz unter die Datenbank vertrieben wird. Für Unternehmen ist die Wirtschaftlichkeit eines Systems von großer Bedeutung. Deshalb bieten Open Source Produkte mit ihren geringen Anschaffungskosten trotz des eingeschränkteren Supports einen hohen Anreiz. Neben der Wirtschaftlichkeit sind Möglichkeiten der Manipulation des Source Code ein Pro für Open Source Produkte. 
Kommerzielle Lizenzen bieten hingegen eine höhere Zukunftssicherheit als Open Source Produkte. Sollten die Entwickler der Open Source Produkte keine Lust oder Zeit mehr haben kann die Entwicklung jederzeit eingestellt werden. 

Unterstütze Programmiersprachen und Betriebssysteme sind Eigenschaften bei denen eine Betrachtung des Ist-Zustandes sinnvoll ist. Im Unternehmen sollte optimaler weise schon Erfahrung in Form von Wissen über die verwendeten Technologien vorhanden sein. Externe Mitarbeiter sowie Schulungen sind teuer und müssen bei der Wahl einer für das Unternehmen unbekannte Technologie berücksichtigt werden. 

Die Frage nach ein Schema stellt sich bei einer Betrachtung der Datenstruktur. Wenn sich die Struktur der abzulegenden Daten häufig ändert oder keine einheitliche Struktur unter den Daten zu erkennen ist, sind Schema freie Datenbanken von Vorteil . Durch Schemafreiheit gewinnt man nämlich an Flexibilität. Wohingegen man durch die Nutzung eines Schemas eine bessere Kontrolle der Daten im DBMS besitzt.  


\begin{table}[H]
\tiny
\caption{Gegenüberstellung von den Charakteristika der Datenbanken}
\label{tb_charakteristika}
\setlength{\tabcolsep}{1mm}
\begin{tabulary} {\linewidth} {C | C | C | C | C | C | C | C | C}
\toprule
Eigenschaft & HBase & Cassandra & CouchDB & MongoDB & Redis & Voldemort & VoltDB & H2 \\  
\midrule
Release Datum & 2008 & 2008 & 2005 & 2009 & 2009 & 2009 & 2010 & 2004 \\
\midrule
Datenbankmodell & Wide Column & Wide Column & Document & Document & Key-Value & Key-Value& Relational DBMS & Relational DBMS \\
\midrule
Lizenz & Open Source & Open Source & Open Source & Open Source & Open Source & Open Source & Kommerziell & Open Source \\
\midrule
Server Betriebssysteme & Linux, Unix, Windows & BSD, Linux, OS X, Windows & Android, BSD, Linux, OS X, Solaris, Windows & Linux, OS X, Solaris, Windows & BSD, Linux, OS X, Windows & Linux, Unix, Windows & Linux, OS X & plattformunabhängig \\
\midrule
Daten-schema & schemafrei & schemafrei & schemafrei & schemafrei & schemafrei & schemafrei & ja & ja \\
\midrule
Typisierung & nein & ja & nein & ja & nein & nein & ja & ja \\
\midrule
Sekundärindizes & nein & eingeschränkt & ja (über Views) & ja & nein & nein & ja & ja \\
\midrule
SQL & nein & nein & nein & nein & nein & nein & ja & ja \\
\midrule
APIs und andere Zugriffskonzepte & Java API, RESTful HTTP API, Thrift & Proprietäres Protokoll (CQL) & RESTful HTTP/JSON API & Proprietäres Protokoll basierend auf JSON & Proprietäres Protokoll & Proprietäres Protokoll & Java API, RESTful HTTP/JSON API, JDBC & Java API, ODBC, JDBC \\
\midrule
Unterstützte Programmiersprachen & C, C\#, C++, Groovy, Java, PHP, Python, Scala & C\#, C++, Java, Perl, PHP, Python, Ruby, +5 & C, C\#, Java, JavaScript, Perl, PHP, PL/SQL, Python, Ruby, +9 & C\#, C++, Java, JavaScript, Perl, PHP, Python, Ruby, +4 & C\#, C++, Java, JavaScript, Perl, PHP, Python, Ruby, +12 & C\#, C++, Java, Perl, PHP, Python, Ruby, +8 & C\#, C++, Java, PHP, Python & C\#, C++, Java, PHP, Phyton \\
\midrule
MapReduce & ja & ja & ja & ja & nein & nein & nein & nein \\
\midrule
Konsistenzkonzept & Immediate Consistency & Eventual Consistency, Immediate Consistency & Eventual
Consistency & Eventual Consistency, Immediate Consistency & Eventual Consistency & Strict Consitency, Eventual Consistency &  Integritätsbedingungen & Integritätsbedingungen \\
\midrule
Transaktionskonzept & nein & nein & nein & nein & optimistisches Locking & nein & ACID & ACID \\
\midrule
Nebenläufigkeit & ja & ja & ja & ja & ja & ja & ja & ja \\
\midrule
Embeddable & nein & ja & ja & nein & nein & ja & ja & ja \\
\midrule
In Memory fähig & nein & nein & nein & nein & ja & hybrid & ja & ja \\
\bottomrule
\end{tabulary}
\end{table}

Sekundärindizes sind gerade in Anbetracht der Forderung nach Performance eine interessante Fähigkeit von Datenbanken. Sie erlauben Indizes auf einem oder mehreren Schlüsseln oder Nicht-Schlüsselattributen, was die Effizienz einer Suche steigern kann. Einige NoSQL Datenbank unterstützen solche Indizes wohingegen relationale Datenbanksysteme in der Regel die Definition beliebiger Sekundärindizes erlauben. 

Typisierungen soll zum Ausdruck bringen ob vordefinierte Datentypen wie Float oder Date in der Datenbank vorhanden sind. Ein Vorteil in der Verwendung von Datentypen ist eine Vorabkontrolle der Daten sodass nur Daten mit den entsprechenden Eigenschaften verwendet werden. Zum Nachteil kann die mangelnde Flexibilität ausgelegt werden. Der Nutzer muss wie beim Schema zwischen Flexibilität und Kontrolle entscheiden. 

Die in der Datenbank verwendet Schnittstelle zur Client-Server Kommunikation spielt bei der Architektur des gesamt Systems eine Rolle. Wird der Applikationsserver z.B. auf dem gleichen Server betrieben wie die Datenbank, ist eine Schnittstelle die nur über das Netzwerk angesprochen werden kann nicht sehr sinnvoll. Wird die Datenbank hingegen über das Netzwerk von eventuell mehreren Servern angesprochen, so eignet sich der Einsatz von REST-Protokollen. 

Die Entscheidung ob eine gewisse Stärke der Konsistenz ausreichend ist wird durch den Anwendungsfall bestimmt. In manchen Anwendungen ist es schlichtweg egal ob Daten redundant sind oder nicht. Die darüberliegende Anwendungsschicht muss bei Inkonsistenz damit rechnen sonst kann es zu schwerwiegenden Fehlern kommen. Beim Transaktionskonzept verhält es sich wie bei der Konsistenz, es hängt vom Anwendungsfall ab. Nebenläufigkeit gibt lediglich an ob gleichzeitig ausgeführte Datenmanipulation durch die Datenbank unterstützt wird.   

Ob eine Datenbank im Embedded Modus betrieben werden kann ist von Bedeutung wenn eine Integration in die Anwendung gewünscht ist. Dadurch können z.B. Verzögerungen durch Netzwerkzugriffe bei der Datenabfrage vermieden werden. 

Die Eigenschaft In Memory spiegelt den Wunsch der CAS Software AG wieder. Sie stellt somit einen der wichtigsten Kriterien für die Auswahl der Datenbank dar.

%% ===========================
\section{Ergebnisfindung}
\label{ch:AnalyseDatenbanken:sec:Ergebniss}
%% ===========================

Jede Datenbank hat seine eigenen Stärken und Schwächen. Bei der Wahl der passenden Datenbank ist nicht entscheiden welche Datenbank im Vergleich zur anderen die Beste ist. Vielmehr ist von entscheidender Bedeutung ob die entsprechende Datenbank den Anforderungen an das Gesamt System gerecht werden kann. 

Dementsprechend ist in diesem Anwendungsfall die Performance einer Datenbank am bedeutsamsten. Die Verwendung des Hauptspeichers als Primärspeicher bedeutet einen theoretischen Geschwindigkeitsvorteil um den Faktor 100.000. In der Realität ist dieser Faktor meist zwar nicht zu erreichen jedoch ergibt sich für Datenbanken die dies ausnützen können ein Vorteil gegenüber anderen. Fünf der Neun Datenbanken bieten diese Möglichkeit nicht. Deswegen ist zu klären ob diese Datenbanken andere Charakteristiken aufweisen können um diesen Nachteil auszugleichen.

Cassandra und HBase ermöglichen hohe Performance durch horizontale Skalierung. Sie erlauben es durch hinzunahmen von Servern zusätzliche Leistung zu erzielen. Die Kunden der CAS Software AG sind alles mittelständische Unternehmen, welche nicht an die Nutzerzahlen von Facebook und Google herankommen. Daher sind wenige Zugriffe zu erwarten. Vorteile durch mögliche horizontale Skalierung fallen somit weg. Es ist zu erwarten das Cassandra und HBase auf einzelnen Servern nicht an die Performance von In Memory fähigen Datenbanken herankommen. Dies führte zu einer Entscheidung gegen die beiden Vertreter der Wide Column Stores.

Die Document Datenbanken sind zwar auch horizontal Skalierbar kommen jedoch nicht an die Performance von beiden zuvor genannten Datenbanken heran. Ihre Stärke liegt in Ihrer Schema freien Datenhaltung die an dieser Stelle von geringem Wert ist da die Daten eine feste Struktur haben. Außerdem sind Funktion wie SUM werden nicht in der eigenen API mitgeliefert was sie für analytische aufgaben bedingt brauchbar macht. Letztendlich können die CouchDB und MongoDB nicht überzeugen weshalb sind ebenfalls nicht verwendet wurden.

Die Key-Value-Stores ermöglichen mit Ihrer Form der Datenhaltung und der In Memory Fähigkeit hohe Zugriffsgeschwindigkeiten. Was Ihnen jedoch zum Nachteil ausgelegt werden muss ist Ihre mangelnde Komplexität. Sie sind besonders für Punkt Abfragen geeignet. Komplexe Anfragen sind nur durch deren Realisierung in der Logikschicht möglich. Was einen enormen Aufwand mit sich bringen würde. Daher entschied man sich auch gegen die Key-Value-Stores. 

VoltDB ist von den Eigenschaften her ein optimaler Kandidat allerdings nicht Open Source. Die Datenbank konnte dadurch nicht verwendet werden. H2 hingegen ist Open Source und bietet Optionen zum Vorhalten der Tabellen im Hauptspeicher. Davon erhofft man sich hohe Geschwindigkeitsvorteile gegenüber herkömmlichen relationalen Systemen. Durch den Ansatz der relationalen Algebra ist das Arbeiten mit SQL möglich. Das birgt Vorteile da auf bereits bekanntem Wissen aufgebaut werden kann.